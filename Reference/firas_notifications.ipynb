{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytz import timezone\n",
    "from IPython.display import clear_output\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creates artificial return dataframe to use in notification. Dataframe\n",
    "To be replaced with global variable of API pull with current data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    global artificial_return\n",
    "    artificial_return = pd.DataFrame({\"Artificail_Return\": np.random.normal\n",
    "                                      (loc = 0.1/252, scale = 0.2/(252**0.5), size = 100000)})\n",
    "    dates = pd.date_range(start = ( datetime.datetime.today() - pd.DateOffset(seconds=99999)), \n",
    "                          end= datetime.datetime.today(), \n",
    "                          tz = \"US/Pacific\",\n",
    "                         freq = \"S\")\n",
    "    artificial_return[\"date\"] = dates\n",
    "    artificial_return.date = pd.to_datetime(artificial_return.date.dt.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    artificial_return.set_index(\"date\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_time(df):\n",
    "    global max_date\n",
    "    try:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            max_date = df.iloc[-1].name\n",
    "    except:\n",
    "        return(\"Please check dates\")\n",
    "    max_date = pd.to_datetime(max_date).tz_localize('US/Eastern')\n",
    "    print(\"Max time found in database\", max_date)\n",
    "    max_date = int(int(max_date.asm8)/1e6) # match date length of apis parameters which is 13 digits long\n",
    "    max_date = int(max_date + 1e3) #skip 1 minute past last max date + 1e4*6(1min) (1e3 is one second)\n",
    "def unix_to_date(unix):\n",
    "    return pd.to_datetime(unix, unit = \"ms\").tz_localize('UTC').tz_convert('US/Eastern')\n",
    "def date_to_unix(date):\n",
    "    try:\n",
    "        return int(int(pd.to_datetime(str(date)).tz_localize('US/Eastern').asm8)/1e6)\n",
    "    except:\n",
    "        return int(int(pd.to_datetime(str(date)).tz_convert('US/Eastern').asm8)/1e6)\n",
    "def check_value(current_price, mean_price):\n",
    "     if current_price > mean_price:\n",
    "        return \"Overvalued\"\n",
    "    elif current_price < mean_price:\n",
    "        return \"Undervalued\"\n",
    "    else:\n",
    "        return \"Price is at mean value.\"\n",
    "def fetch_streams():\n",
    "    global updates\n",
    "    print(f\"**************Fetching new price streams as last date found {str(unix_to_date(max_date))}**************\")\n",
    "    new_feed_times = pd.date_range(start = unix_to_date(max_date), \n",
    "                      end= datetime.datetime.now(timezone('US/Eastern')), \n",
    "                      tz = \"US/Eastern\",\n",
    "                     freq = \"S\")\n",
    "    updates = pd.DataFrame({\"Artificail_Return\": np.random.normal(loc = np.mean(artificial_return.values), \n",
    "                                                                  scale = np.std(artificial_return.values), size = len(new_feed_times))})\n",
    "    updates[\"date\"] = new_feed_times\n",
    "    updates.date = pd.to_datetime(updates.date.dt.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    updates.set_index(\"date\", inplace = True)\n",
    "def conditions(row):\n",
    "    return [\n",
    "        \"background-color: red; color: white\"\n",
    "        if cell<= 0.0\n",
    "        else  \"background-color: green; color: white\"\n",
    "        for cell in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, ssl, smtplib, os\n",
    "import pandas as pd\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.header import Header\n",
    "\n",
    "# DATA_PATH = \"../models_DB.h5\"\n",
    "\n",
    "def send_email(check_trend):\n",
    "    # with pd.HDFStore(DATA_PATH) as store:\n",
    "    #     max_date = store['predictions/news/daily'].index.get_level_values(0).max().strftime('%Y-%m-%d')\n",
    "    #     labels = store['predictions/news/daily'].loc[max_date]\n",
    "    #     labels = labels[labels.BUY_V1 != labels.BUY_V2]\n",
    "    #     labels.to_csv('%s_Predicitions.csv'% max_date)\n",
    "\n",
    "    user = \"firobeid92@gmail.com\"\n",
    "    key = \"******\"\n",
    "    # students = list(pd.read_csv(r\"C:\\Users\\feras.FIROMEGAPC\\Desktop\\Job Related\\2U\\Cohorts\\Berkely\\UCB-VIRT-FIN-PT-09-2022-U-B\\students.csv\").loc[:,\"Emails\"].dropna())\n",
    "    to = ['feras.obeid@lau.edu'] #+ students\n",
    "\n",
    "    subject = 'Updates for %s' % unix_to_date(max_date)\n",
    "    email_body = \"\"\"\\\n",
    "    Hello, \n",
    "    The stock is %s, an order will be submitted based on that!\n",
    "\n",
    "    Yours Sincerely,\n",
    "    Firas's Algo Streamer\"\"\"%check_trend\n",
    "\n",
    "    # attachment = '%s_Predicitions.csv'% max_date\n",
    "    ### Define email ###\n",
    "    message = MIMEMultipart()\n",
    "    message['From'] = Header(user.split(\"@\")[0])\n",
    "    # message['To'] = Header(to)     \n",
    "    message['Subject'] = Header(subject)\n",
    "    message.attach(MIMEText(email_body, 'plain', 'utf-8'))\n",
    "    # att_name = os.path.basename(attachment)\n",
    "    # att1 = MIMEText(open(attachment, 'rb').read(), 'base64', 'utf-8')\n",
    "    # att1['Content-Type'] = 'application/octet-stream'\n",
    "    # att1['Content-Disposition'] = 'attachment; filename=' + att_name\n",
    "    # message.attach(att1)\n",
    "    context = ssl.create_default_context()\n",
    "    email_port = 465\n",
    "    with smtplib.SMTP_SSL(host = \"smtp.gmail.com\", port = email_port, context = context) as server:\n",
    "        server.login(user, key)\n",
    "        print(server.ehlo())\n",
    "        if server.ehlo()[0] == 250:\n",
    "            server.sendmail(key,to, message.as_string())\n",
    "            print('Email sent successfully!')\n",
    "            # os.remove('%s_Predicitions.csv'% max_date)\n",
    "            server.quit()\n",
    "        else:\n",
    "            print(f'Unable to establish connection with server! Error code: {server.ehlo()[0]}')\n",
    "            server.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    global artificial_return\n",
    "    init()\n",
    "    get_max_time(artificial_return)\n",
    "\n",
    "    while max_date < date_to_unix(datetime.datetime.now(timezone('US/Eastern')).strftime(\"%Y-%m-%d %H:%M:%S\")) + 1e4*6: #add extra 1e4*6 1 min latency\n",
    "        # Get most recent second data since init() till exactly now\n",
    "        fetch_streams()\n",
    "        # \n",
    "        display(updates.style.apply(conditions))\n",
    "        #Get Last date from temp df for memory efficiny \n",
    "        get_max_time(updates)\n",
    "        #Append to the original df to keep track of all returns \n",
    "        artificial_return = artificial_return.append(updates)\n",
    "        # Calculate if current prices coming in are greater then previous one's\n",
    "        print(round(np.mean(updates.values),6))\n",
    "        print(round(np.mean(artificial_return.values),6))\n",
    "        check_trend = check_value(round(np.mean(updates.values),6), round(np.mean(artificial_return.values),6))\n",
    "        print(check_trend)\n",
    "        sdf = Random(interval='200ms', freq='50ms')\n",
    "        # clear_output(wait=True)\n",
    "        sleep(1)\n",
    "        # if check_trend == \"Undervalued\":\n",
    "        #     send_email(check_trend)\n",
    "        # elif check_trend == \"Overvalued\":\n",
    "        #     send_email(check_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev)",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
